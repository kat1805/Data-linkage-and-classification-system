import numpy as np
from sklearn.preprocessing import PolynomialFeatures
import pandas as pd
from sklearn import preprocessing
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.model_selection import train_test_split
from sklearn import neighbors
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler

#Reading the csv files and filtering to remove unecessary values
world = pd.read_csv("world.csv",encoding='ISO-8859-1', na_values =['..'])
life = pd.read_csv("life.csv", encoding='ISO-8859-1')

#Mergingthe two datasets based on country codes
result = world.merge(life, on = 'Country Code', how = 'inner')

#Replacing the nan values with median and removing columns with duplicate information 
result.fillna(result.median(), inplace=True)
result.sort_values('Country Code', inplace = True)
result.drop('Country', inplace=True, axis=1)
result.drop('Year', inplace=True, axis=1)

#Separating the features and the target column 
data = result[['Access to electricity (% of population) [EG.ELC.ACCS.ZS]','Adjusted net national income per capita (current US$) [NY.ADJ.NNTY.PC.CD]','Age dependency ratio (% of working-age population) [SP.POP.DPND]','Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total) [SH.DTH.COMM.ZS]','Current health expenditure per capita (current US$) [SH.XPD.CHEX.PC.CD]','Fertility rate, total (births per woman) [SP.DYN.TFRT.IN]','Fixed broadband subscriptions (per 100 people) [IT.NET.BBND.P2]','Fixed telephone subscriptions (per 100 people) [IT.MLT.MAIN.P2]','GDP per capita (constant 2010 US$) [NY.GDP.PCAP.KD]','GNI per capita, Atlas method (current US$) [NY.GNP.PCAP.CD]','Individuals using the Internet (% of population) [IT.NET.USER.ZS]','Lifetime risk of maternal death (%) [SH.MMR.RISK.ZS]','People using at least basic drinking water services (% of population) [SH.H2O.BASW.ZS]','People using at least basic drinking water services, rural (% of rural population) [SH.H2O.BASW.RU.ZS]','People using at least basic drinking water services, urban (% of urban population) [SH.H2O.BASW.UR.ZS]','People using at least basic sanitation services, urban (% of urban population) [SH.STA.BASS.UR.ZS]','Prevalence of anemia among children (% of children under 5) [SH.ANM.CHLD.ZS]','Secure Internet servers (per 1 million people) [IT.NET.SECR.P6]','Self-employed, female (% of female employment) (modeled ILO estimate) [SL.EMP.SELF.FE.ZS]','Wage and salaried workers, female (% of female employment) (modeled ILO estimate) [SL.EMP.WORK.FE.ZS]']].astype(float)
classlabel = result['Life expectancy at birth (years)']

#Getting the SSE to caluclate the no. of clusters using the Elbow method 
sum_of_square = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(data)
    sum_of_square.append(kmeans.inertia_)
    
#Plotting the SSE on a graph to identify the no. of clusters 
plt.plot(range(1, 11), sum_of_square)
plt.xticks(range(1, 11))
plt.xlabel("Number of Clusters")
plt.ylabel("Sum of Square")
plt.title('Elbow Method for no. of cluster selection')
plt.savefig("task2bgraph1.png", dpi = 100)
plt.show()
print('\n')

#The Elbow method gives no.of clusters=3
#Fit the data using the Kmeans 
kmeans = KMeans(n_clusters=3).fit(data)
kmeans.labels_
pred_1 = kmeans.predict(data)
pred_1 = pd.DataFrame(pred_1)
pred_1.columns = ['fclusterlabel']

#Printing the new feature generated by clustering 
print('Feature engineered from clustering:')
print(pred_1)
print('\n')

#Creating new features using interaction pairs 
new_features = PolynomialFeatures(degree=2, interaction_only = True, include_bias = False)
new = new_features.fit_transform(data)

#Getting the names of the new features 
features = new_features.get_feature_names(['Access to electricity (% of population) [EG.ELC.ACCS.ZS]','Adjusted net national income per capita (current US$) [NY.ADJ.NNTY.PC.CD]','Age dependency ratio (% of working-age population) [SP.POP.DPND]','Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total) [SH.DTH.COMM.ZS]','Current health expenditure per capita (current US$) [SH.XPD.CHEX.PC.CD]','Fertility rate, total (births per woman) [SP.DYN.TFRT.IN]','Fixed broadband subscriptions (per 100 people) [IT.NET.BBND.P2]','Fixed telephone subscriptions (per 100 people) [IT.MLT.MAIN.P2]','GDP per capita (constant 2010 US$) [NY.GDP.PCAP.KD]','GNI per capita, Atlas method (current US$) [NY.GNP.PCAP.CD]','Individuals using the Internet (% of population) [IT.NET.USER.ZS]','Lifetime risk of maternal death (%) [SH.MMR.RISK.ZS]','People using at least basic drinking water services (% of population) [SH.H2O.BASW.ZS]','People using at least basic drinking water services, rural (% of rural population) [SH.H2O.BASW.RU.ZS]','People using at least basic drinking water services, urban (% of urban population) [SH.H2O.BASW.UR.ZS]','People using at least basic sanitation services, urban (% of urban population) [SH.STA.BASS.UR.ZS]','Prevalence of anemia among children (% of children under 5) [SH.ANM.CHLD.ZS]','Secure Internet servers (per 1 million people) [IT.NET.SECR.P6]','Self-employed, female (% of female employment) (modeled ILO estimate) [SL.EMP.SELF.FE.ZS]','Wage and salaried workers, female (% of female employment) (modeled ILO estimate) [SL.EMP.WORK.FE.ZS]'])

#Appending the names of the new features to the columns and adding the feature generated by clustering to the dataset
new = pd.DataFrame(new)
#Printing the dataset with the old and the new features
print('Dataset containing the old features and the new features engineered by interaction pairs:')
print('\n')
print(new.head())
new.columns = features
new['fclusterlabel'] = pred_1['fclusterlabel']

#Calculating the correlation between all the 211 features
cor_matrix = new.corr().abs()
upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))

#Saving the columns having high correlation in a list 
to_drop = [column for column in upper_tri.columns if any(upper_tri[column] >= 0.5)] 

#Getting the indices of the highly correlated columns 
indices = []
for name in to_drop:
    index_no = new.columns.get_loc(name)
    indices.append(index_no)

print('Columns to drop:')
print(indices)
print('\n')
#Dropping the columns having high correlation from the dataset
df1 = new.drop(new.columns[indices], axis=1)

#Appending the target column to the dataset
df1['Life expectancy at birth (years)'] = result['Life expectancy at birth (years)']

#Separating the features and the target column
X = df1.drop('Life expectancy at birth (years)',1) 
y = df1['Life expectancy at birth (years)']

#Applying SelectKBest to extract top 4 best features
bestfeatures = SelectKBest(score_func=chi2, k=4)
fit = bestfeatures.fit(X,y)
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)

#Concatenating the column names and the scores 
featureScores = pd.concat([dfcolumns,dfscores],axis=1)
featureScores.columns = ['Specs','Score']  

#Printing the 4 best features 
print(featureScores.nlargest(4,'Score'))  
print('\n')

#Saving the indices of the 4 best features in a list 
columns = [1, 2, 0, 3]
four_features = df1[df1.columns[columns]]

#Splitting the data into training and testing sets
X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(four_features, classlabel, train_size=0.70, test_size=0.30, random_state = 250)

#Scaling the data
scaler = preprocessing.MinMaxScaler().fit(X_train_1)
X_train_1=scaler.transform(X_train_1)
X_test_1=scaler.transform(X_test_1)

#Applying the 3NN classification 
knn = neighbors.KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_1, y_train_1)
y_pred_1=knn.predict(X_test_1)

#Calculating and printing the accuracy score of feature engineering 
print("Accuracy of feature engineering: ",round(accuracy_score(y_test_1, y_pred_1), 3))

#PCA
#Separating the features and the target column 
X1= result[['Access to electricity (% of population) [EG.ELC.ACCS.ZS]','Adjusted net national income per capita (current US$) [NY.ADJ.NNTY.PC.CD]','Age dependency ratio (% of working-age population) [SP.POP.DPND]','Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total) [SH.DTH.COMM.ZS]','Current health expenditure per capita (current US$) [SH.XPD.CHEX.PC.CD]','Fertility rate, total (births per woman) [SP.DYN.TFRT.IN]','Fixed broadband subscriptions (per 100 people) [IT.NET.BBND.P2]','Fixed telephone subscriptions (per 100 people) [IT.MLT.MAIN.P2]','GDP per capita (constant 2010 US$) [NY.GDP.PCAP.KD]','GNI per capita, Atlas method (current US$) [NY.GNP.PCAP.CD]','Individuals using the Internet (% of population) [IT.NET.USER.ZS]','Lifetime risk of maternal death (%) [SH.MMR.RISK.ZS]','People using at least basic drinking water services (% of population) [SH.H2O.BASW.ZS]','People using at least basic drinking water services, rural (% of rural population) [SH.H2O.BASW.RU.ZS]','People using at least basic drinking water services, urban (% of urban population) [SH.H2O.BASW.UR.ZS]','People using at least basic sanitation services, urban (% of urban population) [SH.STA.BASS.UR.ZS]','Prevalence of anemia among children (% of children under 5) [SH.ANM.CHLD.ZS]','Secure Internet servers (per 1 million people) [IT.NET.SECR.P6]','Self-employed, female (% of female employment) (modeled ILO estimate) [SL.EMP.SELF.FE.ZS]','Wage and salaried workers, female (% of female employment) (modeled ILO estimate) [SL.EMP.WORK.FE.ZS]']].astype(float)
y1= result['Life expectancy at birth (years)']

#Performing 3-NN 
X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X1, y1, train_size=0.70, test_size=0.30, random_state=250)

#Scaling the data 
scaler = preprocessing.MinMaxScaler().fit(X_train_2)
X_train_2=scaler.transform(X_train_2)
X_test_2=scaler.transform(X_test_2)

#Applying the PCA method 
pca = PCA(n_components=4)
X_train_2 = pca.fit_transform(X_train_2)
X_test_2 = pca.transform(X_test_2)

knn = neighbors.KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_2, y_train_2)
y_pred_2=knn.predict(X_test_2)

#Printing the accuracy score of PCA
print("Accuracy of PCA: ",round(accuracy_score(y_test_2, y_pred_2), 3))


#FIRST FOUR FEATURES
#Separating the features and the target column 
data_1=result[['Access to electricity (% of population) [EG.ELC.ACCS.ZS]','Adjusted net national income per capita (current US$) [NY.ADJ.NNTY.PC.CD]','Age dependency ratio (% of working-age population) [SP.POP.DPND]','Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total) [SH.DTH.COMM.ZS]']]
classlabel = result['Life expectancy at birth (years)']
X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(data_1, classlabel, train_size=0.70, test_size=0.30, random_state=250)

#Scaling the data
scaler = preprocessing.MinMaxScaler().fit(X_train_3)
X_train_3=scaler.transform(X_train_3)
X_test_3=scaler.transform(X_test_3)

knn = neighbors.KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_3, y_train_3)
y_pred_3=knn.predict(X_test_3)

# Printing the accuracy score of first four features 
print("Accuracy of first four features: ",round(accuracy_score(y_test_3, y_pred_3), 3))
